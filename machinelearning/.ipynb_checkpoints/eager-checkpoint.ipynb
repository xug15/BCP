{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CCQY7jpBfMur"
   },
   "source": [
    "##### Copyright 2018 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2022-06-03T19:27:57.658452Z",
     "iopub.status.busy": "2022-06-03T19:27:57.657946Z",
     "iopub.status.idle": "2022-06-03T19:27:57.661600Z",
     "shell.execute_reply": "2022-06-03T19:27:57.661008Z"
    },
    "id": "z6X9omPnfO_h"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2QQJJyDzqGRb"
   },
   "source": [
    "# Eager Execution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B1xdylywqUSX"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td><a target=\"_blank\" href=\"https://tensorflow.google.cn/guide/eager\"><img src=\"https://tensorflow.google.cn/images/tf_logo_32px.png\">在 TensorFlow.org 上查看 </a></td>\n",
    "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/zh-cn/guide/eager.ipynb\"><img src=\"https://tensorflow.google.cn/images/colab_logo_32px.png\">在 Google Colab 中运行 </a></td>\n",
    "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/zh-cn/guide/eager.ipynb\"><img src=\"https://tensorflow.google.cn/images/GitHub-Mark-32px.png\">在 GitHub 上查看源代码</a>   </td>\n",
    "  <td><a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/zh-cn/guide/eager.ipynb\"><img src=\"https://tensorflow.google.cn/images/download_logo_32px.png\">下载笔记本</a></td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EGjDcGxIqEfX"
   },
   "source": [
    "TensorFlow 的 Eager Execution 是一种命令式编程环境，可立即评估运算，无需构建计算图：运算会返回具体的值，而非构建供稍后运行的计算图。这样能使您轻松入门 TensorFlow 并调试模型，同时也减少了样板代码。要跟随本指南进行学习，请在交互式 `python` 解释器中运行以下代码示例。\n",
    "\n",
    "Eager Execution 是用于研究和实验的灵活机器学习平台，具备以下特性：\n",
    "\n",
    "- *直观的界面* - 自然地组织代码结构并使用 Python 数据结构。快速迭代小模型和小数据。\n",
    "- *更方便的调试功能* - 直接调用运算以检查正在运行的模型并测试更改。使用标准 Python 调试工具立即报告错误。\n",
    "- *自然的控制流* - 使用 Python 而非计算图控制流，简化了动态模型的规范。\n",
    "\n",
    "Eager Execution 支持大部分 TensorFlow 运算和 GPU 加速。\n",
    "\n",
    "注：启用 Eager Execution 后可能会增加某些模型的开销。我们正在持续改进其性能，如果您遇到问题，请[提交错误报告](https://github.com/tensorflow/tensorflow/issues)并分享您的基准。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RBAeIwOMrYk8"
   },
   "source": [
    "## 设置和基本用法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T19:27:57.665221Z",
     "iopub.status.busy": "2022-06-03T19:27:57.664708Z",
     "iopub.status.idle": "2022-06-03T19:27:59.461234Z",
     "shell.execute_reply": "2022-06-03T19:27:59.460097Z"
    },
    "id": "ByNsp4VqqEfa"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import cProfile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set the tensorfolw version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\software\\annoconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\software\\annoconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\software\\annoconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\software\\annoconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\software\\annoconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\software\\annoconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'Hello, TensorFlow!'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "tf.add(1, 2)\n",
    "\n",
    "hello = tf.constant('Hello, TensorFlow!')\n",
    "hello.numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "48P3-8q4qEfe"
   },
   "source": [
    "在 Tensorflow 2.0 中，默认启用 Eager Execution。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T19:27:59.468292Z",
     "iopub.status.busy": "2022-06-03T19:27:59.467249Z",
     "iopub.status.idle": "2022-06-03T19:27:59.488559Z",
     "shell.execute_reply": "2022-06-03T19:27:59.487952Z"
    },
    "id": "7aFsD8csqEff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x_G1zZT5qEfh"
   },
   "source": [
    "现在您可以运行 TensorFlow 运算，结果将立即返回："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T19:27:59.511305Z",
     "iopub.status.busy": "2022-06-03T19:27:59.510798Z",
     "iopub.status.idle": "2022-06-03T19:28:02.732250Z",
     "shell.execute_reply": "2022-06-03T19:28:02.731493Z"
    },
    "id": "9gsI54pbqEfj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello, [[4.]]\n"
     ]
    }
   ],
   "source": [
    "x = [[2.]]\n",
    "m = tf.matmul(x, x)\n",
    "print(\"hello, {}\".format(m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ajFn6qsdqEfl"
   },
   "source": [
    "启用 Eager Execution 会改变 TensorFlow 运算的行为方式 - 现在它们会立即评估并将值返回给 Python。`tf.Tensor` 对象会引用具体值，而非指向计算图中节点的符号句柄。由于无需构建计算图并稍后在会话中运行，可以轻松使用 `print()` 或调试程序检查结果。评估、输出和检查张量值不会中断计算梯度的流程。\n",
    "\n",
    "Eager Execution 可以很好地配合 [NumPy](http://www.numpy.org/) 使用。NumPy 运算接受 `tf.Tensor` 参数。TensorFlow `tf.math` 运算会将 Python 对象和 NumPy 数组转换为 `tf.Tensor` 对象。`tf.Tensor.numpy` 方法会以 NumPy `ndarray` 的形式返回该对象的值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T19:28:02.735960Z",
     "iopub.status.busy": "2022-06-03T19:28:02.735409Z",
     "iopub.status.idle": "2022-06-03T19:28:02.739615Z",
     "shell.execute_reply": "2022-06-03T19:28:02.739005Z"
    },
    "id": "sTO0_5TYqz1n"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 2]\n",
      " [3 4]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([[1, 2],\n",
    "                 [3, 4]])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T19:28:02.742725Z",
     "iopub.status.busy": "2022-06-03T19:28:02.742204Z",
     "iopub.status.idle": "2022-06-03T19:28:02.746950Z",
     "shell.execute_reply": "2022-06-03T19:28:02.746403Z"
    },
    "id": "Dp14YT8Gq4r1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[2 3]\n",
      " [4 5]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Broadcasting support\n",
    "b = tf.add(a, 1)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T19:28:02.749797Z",
     "iopub.status.busy": "2022-06-03T19:28:02.749311Z",
     "iopub.status.idle": "2022-06-03T19:28:02.752866Z",
     "shell.execute_reply": "2022-06-03T19:28:02.752265Z"
    },
    "id": "69p3waMfq8cQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 2  6]\n",
      " [12 20]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Operator overloading is supported\n",
    "print(a * b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T19:28:02.755866Z",
     "iopub.status.busy": "2022-06-03T19:28:02.755318Z",
     "iopub.status.idle": "2022-06-03T19:28:02.759000Z",
     "shell.execute_reply": "2022-06-03T19:28:02.758344Z"
    },
    "id": "Ui025t1qqEfm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2  6]\n",
      " [12 20]]\n"
     ]
    }
   ],
   "source": [
    "# Use NumPy values\n",
    "import numpy as np\n",
    "\n",
    "c = np.multiply(a, b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T19:28:02.761682Z",
     "iopub.status.busy": "2022-06-03T19:28:02.761209Z",
     "iopub.status.idle": "2022-06-03T19:28:02.764591Z",
     "shell.execute_reply": "2022-06-03T19:28:02.764017Z"
    },
    "id": "Tq_aFRzWrCua"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 2]\n",
      " [3 4]], shape=(2, 2), dtype=int32)\n",
      "[[1 2]\n",
      " [3 4]]\n"
     ]
    }
   ],
   "source": [
    "# Obtain numpy value from a tensor:\n",
    "print(a)\n",
    "print(a.numpy())\n",
    "# => [[1 2]\n",
    "#     [3 4]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H08f9ss9qEft"
   },
   "source": [
    "## 动态控制流\n",
    "\n",
    "Eager Execution 的一个主要优势是，在执行模型时，主机语言的所有功能均可用。因此，编写 [fizzbuzz](https://en.wikipedia.org/wiki/Fizz_buzz) 之类的代码会很容易："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T19:28:02.767389Z",
     "iopub.status.busy": "2022-06-03T19:28:02.766950Z",
     "iopub.status.idle": "2022-06-03T19:28:02.771208Z",
     "shell.execute_reply": "2022-06-03T19:28:02.770667Z"
    },
    "id": "0fudRMeUqEfu"
   },
   "outputs": [],
   "source": [
    "def fizzbuzz(max_num):\n",
    "  counter = tf.constant(0)\n",
    "  max_num = tf.convert_to_tensor(max_num)\n",
    "  for num in range(1, max_num.numpy()+1):\n",
    "    num = tf.constant(num)\n",
    "    if int(num % 3) == 0 and int(num % 5) == 0:\n",
    "      print('FizzBuzz')\n",
    "    elif int(num % 3) == 0:\n",
    "      print('Fizz')\n",
    "    elif int(num % 5) == 0:\n",
    "      print('Buzz')\n",
    "    else:\n",
    "      print(num.numpy())\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T19:28:02.774317Z",
     "iopub.status.busy": "2022-06-03T19:28:02.773705Z",
     "iopub.status.idle": "2022-06-03T19:28:02.779547Z",
     "shell.execute_reply": "2022-06-03T19:28:02.778993Z"
    },
    "id": "P2cKknQWrJLB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "Fizz\n",
      "4\n",
      "Buzz\n",
      "Fizz\n",
      "7\n",
      "8\n",
      "Fizz\n",
      "Buzz\n",
      "11\n",
      "Fizz\n",
      "13\n",
      "14\n",
      "FizzBuzz\n"
     ]
    }
   ],
   "source": [
    "fizzbuzz(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7kA-aC3BqEfy"
   },
   "source": [
    "这段代码具有依赖于张量值的条件语句并会在运行时输出这些值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8huKpuuAwICq"
   },
   "source": [
    "## Eager 训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mp2lCCZYrxHd"
   },
   "source": [
    "### 计算梯度\n",
    "\n",
    "[自动微分](https://en.wikipedia.org/wiki/Automatic_differentiation)对实现机器学习算法（例如用于训练神经网络的[反向传播](https://en.wikipedia.org/wiki/Backpropagation)）十分有用。在 Eager Execution 期间，请使用 `tf.GradientTape` 跟踪运算以便稍后计算梯度。\n",
    "\n",
    "您可以在 Eager Execution 中使用 `tf.GradientTape` 来训练和/或计算梯度。这对复杂的训练循环特别有用。\n",
    "\n",
    "由于在每次调用期间都可能进行不同运算，所有前向传递的运算都会记录到“条带”中。要计算梯度，请反向播放条带，然后丢弃。特定 `tf.GradientTape` 只能计算一个梯度；后续调用会引发运行时错误。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T19:28:02.782324Z",
     "iopub.status.busy": "2022-06-03T19:28:02.782095Z",
     "iopub.status.idle": "2022-06-03T19:28:02.790136Z",
     "shell.execute_reply": "2022-06-03T19:28:02.789548Z"
    },
    "id": "7g1yWiSXqEf-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[2.]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "w = tf.Variable([[1.0]])\n",
    "with tf.GradientTape() as tape:\n",
    "  loss = w * w\n",
    "\n",
    "grad = tape.gradient(loss, w)\n",
    "print(grad)  # => tf.Tensor([[ 2.]], shape=(1, 1), dtype=float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vkHs32GqweYS"
   },
   "source": [
    "### 训练模型\n",
    "\n",
    "以下示例创建了一个多层模型，该模型会对标准 MNIST 手写数字进行分类。示例演示了在 Eager Execution 环境中构建可训练计算图的优化器和层 API。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T19:28:02.793202Z",
     "iopub.status.busy": "2022-06-03T19:28:02.792632Z",
     "iopub.status.idle": "2022-06-03T19:28:03.671138Z",
     "shell.execute_reply": "2022-06-03T19:28:03.670430Z"
    },
    "id": "38kymXZowhhz"
   },
   "outputs": [],
   "source": [
    "# Fetch and format the mnist data\n",
    "(mnist_images, mnist_labels), _ = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(\n",
    "  (tf.cast(mnist_images[...,tf.newaxis]/255, tf.float32),\n",
    "   tf.cast(mnist_labels,tf.int64)))\n",
    "dataset = dataset.shuffle(1000).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T19:28:03.675097Z",
     "iopub.status.busy": "2022-06-03T19:28:03.674519Z",
     "iopub.status.idle": "2022-06-03T19:28:03.712067Z",
     "shell.execute_reply": "2022-06-03T19:28:03.711459Z"
    },
    "id": "rl1K8rOowmwT"
   },
   "outputs": [],
   "source": [
    "# Build the model\n",
    "mnist_model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Conv2D(16,[3,3], activation='relu',\n",
    "                         input_shape=(None, None, 1)),\n",
    "  tf.keras.layers.Conv2D(16,[3,3], activation='relu'),\n",
    "  tf.keras.layers.GlobalAveragePooling2D(),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fvyk-HgGwxwl"
   },
   "source": [
    "即使没有训练，也可以在 Eager Execution 中调用模型并检查输出："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T19:28:03.715287Z",
     "iopub.status.busy": "2022-06-03T19:28:03.714830Z",
     "iopub.status.idle": "2022-06-03T19:28:04.514506Z",
     "shell.execute_reply": "2022-06-03T19:28:04.513641Z"
    },
    "id": "BsxystjBwxLS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits:  [[-0.06774066  0.1566167  -0.03191751 -0.05260115 -0.10423937 -0.05480159\n",
      "   0.03193924  0.21110258 -0.03586184 -0.09425696]]\n"
     ]
    }
   ],
   "source": [
    "for images,labels in dataset.take(1):\n",
    "  print(\"Logits: \", mnist_model(images[0:1]).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\software\\annoconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 6s 96us/sample - loss: 0.2945 - acc: 0.9144\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 6s 95us/sample - loss: 0.1420 - acc: 0.9578\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 6s 95us/sample - loss: 0.1077 - acc: 0.9679\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 6s 95us/sample - loss: 0.0857 - acc: 0.9736\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 6s 95us/sample - loss: 0.0724 - acc: 0.9768\n",
      "10000/10000 [==============================] - 1s 66us/sample - loss: 0.0781 - acc: 0.9760\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07805849118428305, 0.976]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y3PGa8G7qEgB"
   },
   "source": [
    "虽然 Keras 模型有内置训练循环（使用 `fit` 方法），但有时您需要进行更多自定义。下面是一个使用 Eager Execution 实现训练循环的示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T19:28:04.518226Z",
     "iopub.status.busy": "2022-06-03T19:28:04.517626Z",
     "iopub.status.idle": "2022-06-03T19:28:04.521564Z",
     "shell.execute_reply": "2022-06-03T19:28:04.520980Z"
    },
    "id": "bzRhM7JDnaEG"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow._api.v1.keras.losses' has no attribute 'SparseCategoricalCrossentropy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21016\\1560230075.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mloss_object\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSparseCategoricalCrossentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfrom_logits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mloss_history\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow._api.v1.keras.losses' has no attribute 'SparseCategoricalCrossentropy'"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "loss_history = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tXaupYXRI2YM"
   },
   "source": [
    "注：请在 `tf.debugging` 中使用断言函数检查条件是否成立。这在 Eager Execution 和计算图执行中均有效。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T19:28:04.524779Z",
     "iopub.status.busy": "2022-06-03T19:28:04.524342Z",
     "iopub.status.idle": "2022-06-03T19:28:04.528653Z",
     "shell.execute_reply": "2022-06-03T19:28:04.528082Z"
    },
    "id": "DDHrigtiCIA4"
   },
   "outputs": [],
   "source": [
    "def train_step(images, labels):\n",
    "  with tf.GradientTape() as tape:\n",
    "    logits = mnist_model(images, training=True)\n",
    "    \n",
    "    # Add asserts to check the shape of the output.\n",
    "    tf.debugging.assert_equal(logits.shape, (32, 10))\n",
    "    \n",
    "    loss_value = loss_object(labels, logits)\n",
    "\n",
    "  loss_history.append(loss_value.numpy().mean())\n",
    "  grads = tape.gradient(loss_value, mnist_model.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(grads, mnist_model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T19:28:04.531605Z",
     "iopub.status.busy": "2022-06-03T19:28:04.531223Z",
     "iopub.status.idle": "2022-06-03T19:28:04.534901Z",
     "shell.execute_reply": "2022-06-03T19:28:04.534309Z"
    },
    "id": "0m1xAXrmqEgJ"
   },
   "outputs": [],
   "source": [
    "def train(epochs):\n",
    "  for epoch in range(epochs):\n",
    "    for (batch, (images, labels)) in enumerate(dataset):\n",
    "      train_step(images, labels)\n",
    "    print ('Epoch {} finished'.format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T19:28:04.537552Z",
     "iopub.status.busy": "2022-06-03T19:28:04.537194Z",
     "iopub.status.idle": "2022-06-03T19:28:55.068581Z",
     "shell.execute_reply": "2022-06-03T19:28:55.067794Z"
    },
    "id": "C5dGz0p_nf4W"
   },
   "outputs": [],
   "source": [
    "train(epochs = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T19:28:55.072002Z",
     "iopub.status.busy": "2022-06-03T19:28:55.071398Z",
     "iopub.status.idle": "2022-06-03T19:28:55.732059Z",
     "shell.execute_reply": "2022-06-03T19:28:55.731216Z"
    },
    "id": "5vG5ql_2vYB5"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(loss_history)\n",
    "plt.xlabel('Batch #')\n",
    "plt.ylabel('Loss [entropy]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kKpOlHPLqEgl"
   },
   "source": [
    "### 变量和优化器\n",
    "\n",
    "`tf.Variable` 对象会存储在训练期间访问的可变、类似于 `tf.Tensor` 的值，以更简单地实现自动微分。\n",
    "\n",
    "变量的集合及其运算方法可以封装到层或模型中。有关详细信息，请参阅[自定义 Keras 层和模型](https://render.githubusercontent.com/view/keras/custom_layers_and_models.ipynb)。层和模型之间的主要区别在于模型添加了如下方法：`Model.fit`、`Model.evaluate` 和 `Model.save`。\n",
    "\n",
    "例如，上面的自动微分示例可以改写为："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T19:28:55.735471Z",
     "iopub.status.busy": "2022-06-03T19:28:55.734861Z",
     "iopub.status.idle": "2022-06-03T19:28:55.739619Z",
     "shell.execute_reply": "2022-06-03T19:28:55.738860Z"
    },
    "id": "2qXcPngYk8dN"
   },
   "outputs": [],
   "source": [
    "class Linear(tf.keras.Model):\n",
    "  def __init__(self):\n",
    "    super(Linear, self).__init__()\n",
    "    self.W = tf.Variable(5., name='weight')\n",
    "    self.B = tf.Variable(10., name='bias')\n",
    "  def call(self, inputs):\n",
    "    return inputs * self.W + self.B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T19:28:55.742221Z",
     "iopub.status.busy": "2022-06-03T19:28:55.742012Z",
     "iopub.status.idle": "2022-06-03T19:28:55.749205Z",
     "shell.execute_reply": "2022-06-03T19:28:55.748670Z"
    },
    "id": "nnQLBYmEqEgm"
   },
   "outputs": [],
   "source": [
    "# A toy dataset of points around 3 * x + 2\n",
    "NUM_EXAMPLES = 2000\n",
    "training_inputs = tf.random.normal([NUM_EXAMPLES])\n",
    "noise = tf.random.normal([NUM_EXAMPLES])\n",
    "training_outputs = training_inputs * 3 + 2 + noise\n",
    "\n",
    "# The loss function to be optimized\n",
    "def loss(model, inputs, targets):\n",
    "  error = model(inputs) - targets\n",
    "  return tf.reduce_mean(tf.square(error))\n",
    "\n",
    "def grad(model, inputs, targets):\n",
    "  with tf.GradientTape() as tape:\n",
    "    loss_value = loss(model, inputs, targets)\n",
    "  return tape.gradient(loss_value, [model.W, model.B])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q7x1CDurl3IG"
   },
   "source": [
    "下一步：\n",
    "\n",
    "1. 创建模型。\n",
    "2. 损失函数对模型参数的导数。\n",
    "3. 基于导数的变量更新策略。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T19:28:55.752370Z",
     "iopub.status.busy": "2022-06-03T19:28:55.751877Z",
     "iopub.status.idle": "2022-06-03T19:28:56.460354Z",
     "shell.execute_reply": "2022-06-03T19:28:56.459757Z"
    },
    "id": "SbXJk0f2lztg"
   },
   "outputs": [],
   "source": [
    "model = Linear()\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "\n",
    "print(\"Initial loss: {:.3f}\".format(loss(model, training_inputs, training_outputs)))\n",
    "\n",
    "steps = 300\n",
    "for i in range(steps):\n",
    "  grads = grad(model, training_inputs, training_outputs)\n",
    "  optimizer.apply_gradients(zip(grads, [model.W, model.B]))\n",
    "  if i % 20 == 0:\n",
    "    print(\"Loss at step {:03d}: {:.3f}\".format(i, loss(model, training_inputs, training_outputs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T19:28:56.463584Z",
     "iopub.status.busy": "2022-06-03T19:28:56.463106Z",
     "iopub.status.idle": "2022-06-03T19:28:56.467588Z",
     "shell.execute_reply": "2022-06-03T19:28:56.467012Z"
    },
    "id": "PV_dqer7pzSH"
   },
   "outputs": [],
   "source": [
    "print(\"Final loss: {:.3f}\".format(loss(model, training_inputs, training_outputs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T19:28:56.470647Z",
     "iopub.status.busy": "2022-06-03T19:28:56.469968Z",
     "iopub.status.idle": "2022-06-03T19:28:56.474260Z",
     "shell.execute_reply": "2022-06-03T19:28:56.473692Z"
    },
    "id": "rvt_Wj3Tp0hm"
   },
   "outputs": [],
   "source": [
    "print(\"W = {}, B = {}\".format(model.W.numpy(), model.B.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rPjb8nRWqEgr"
   },
   "source": [
    "注：变量将一直存在，直至删除对 Python 对象的最后一个引用，并删除该变量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "scMjg6L6qEgv"
   },
   "source": [
    "### 基于对象的保存\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y-0ZcCcjwkux"
   },
   "source": [
    "`tf.keras.Model` 包括一个方便的 `save_weights` 方法，您可以通过该方法轻松创建检查点： "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T19:28:56.477535Z",
     "iopub.status.busy": "2022-06-03T19:28:56.476943Z",
     "iopub.status.idle": "2022-06-03T19:28:56.487158Z",
     "shell.execute_reply": "2022-06-03T19:28:56.486528Z"
    },
    "id": "oJrMX94PwD9s"
   },
   "outputs": [],
   "source": [
    "model.save_weights('weights')\n",
    "status = model.load_weights('weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2EfTjWV_wEng"
   },
   "source": [
    "您可以使用 `tf.train.Checkpoint` 完全控制此过程。\n",
    "\n",
    "本部分是[检查点训练指南](https://render.githubusercontent.com/view/checkpoint.ipynb)的缩略版。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T19:28:56.490288Z",
     "iopub.status.busy": "2022-06-03T19:28:56.489837Z",
     "iopub.status.idle": "2022-06-03T19:28:56.493463Z",
     "shell.execute_reply": "2022-06-03T19:28:56.492916Z"
    },
    "id": "7z5xRfdHzZOQ"
   },
   "outputs": [],
   "source": [
    "x = tf.Variable(10.)\n",
    "checkpoint = tf.train.Checkpoint(x=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T19:28:56.496351Z",
     "iopub.status.busy": "2022-06-03T19:28:56.495806Z",
     "iopub.status.idle": "2022-06-03T19:28:56.504371Z",
     "shell.execute_reply": "2022-06-03T19:28:56.503738Z"
    },
    "id": "IffrUVG7zyVb"
   },
   "outputs": [],
   "source": [
    "x.assign(2.)   # Assign a new value to the variables and save.\n",
    "checkpoint_path = './ckpt/'\n",
    "checkpoint.save('./ckpt/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T19:28:56.507632Z",
     "iopub.status.busy": "2022-06-03T19:28:56.507051Z",
     "iopub.status.idle": "2022-06-03T19:28:56.513332Z",
     "shell.execute_reply": "2022-06-03T19:28:56.512809Z"
    },
    "id": "eMT9koCoqEgw"
   },
   "outputs": [],
   "source": [
    "x.assign(11.)  # Change the variable after saving.\n",
    "\n",
    "# Restore values from the checkpoint\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_path))\n",
    "\n",
    "print(x)  # => 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vbFnP-yLqEgx"
   },
   "source": [
    "要保存和加载模型，`tf.train.Checkpoint` 会存储对象的内部状态，而无需隐藏变量。要记录 `model`、`optimizer` 和全局步骤的状态，请将它们传递到 `tf.train.Checkpoint`："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T19:28:56.516499Z",
     "iopub.status.busy": "2022-06-03T19:28:56.515968Z",
     "iopub.status.idle": "2022-06-03T19:28:56.531592Z",
     "shell.execute_reply": "2022-06-03T19:28:56.531022Z"
    },
    "id": "hWZHyAXMqEg0"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Conv2D(16,[3,3], activation='relu'),\n",
    "  tf.keras.layers.GlobalAveragePooling2D(),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "checkpoint_dir = 'path/to/model_dir'\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "  os.makedirs(checkpoint_dir)\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "root = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                           model=model)\n",
    "\n",
    "root.save(checkpoint_prefix)\n",
    "root.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R-ITwkBCF6GJ"
   },
   "source": [
    "注：在许多训练循环中，会在调用 `tf.train.Checkpoint.restore` 后创建变量。这些变量将在创建后立即恢复，并且可以使用断言来确保检查点已完全加载。有关详细信息，请参阅[检查点训练指南](https://render.githubusercontent.com/view/checkpoint.ipynb)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3yoD0VJ7qEg3"
   },
   "source": [
    "### 面向对象的指标\n",
    "\n",
    "`tf.keras.metrics` 会被存储为对象。可以通过将新数据传递给可调用对象来更新指标，并使用 `tf.keras.metrics.result` 方法检索结果，例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T19:28:56.534804Z",
     "iopub.status.busy": "2022-06-03T19:28:56.534246Z",
     "iopub.status.idle": "2022-06-03T19:28:56.547772Z",
     "shell.execute_reply": "2022-06-03T19:28:56.547231Z"
    },
    "id": "9ccu0iAaqEg5"
   },
   "outputs": [],
   "source": [
    "m = tf.keras.metrics.Mean(\"loss\")\n",
    "m(0)\n",
    "m(5)\n",
    "m.result()  # => 2.5\n",
    "m([8, 9])\n",
    "m.result()  # => 5.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aB8qWtT955pI"
   },
   "source": [
    "### 摘要和 TensorBoard\n",
    "\n",
    "[TensorBoard](https://tensorflow.google.cn/tensorboard) 是一种可视化工具，用于了解、调试和优化模型训练过程。它使用在执行程序时编写的摘要事件。\n",
    "\n",
    "您可以在 Eager Execution 中使用 `tf.summary` 记录变量摘要。例如，要每 100 个训练步骤记录一次 `loss` 的摘要，请运行以下代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T19:28:56.550693Z",
     "iopub.status.busy": "2022-06-03T19:28:56.550260Z",
     "iopub.status.idle": "2022-06-03T19:28:56.562701Z",
     "shell.execute_reply": "2022-06-03T19:28:56.562151Z"
    },
    "id": "z6VInqhA6RH4"
   },
   "outputs": [],
   "source": [
    "logdir = \"./tb/\"\n",
    "writer = tf.summary.create_file_writer(logdir)\n",
    "\n",
    "steps = 1000\n",
    "with writer.as_default():  # or call writer.set_as_default() before the loop.\n",
    "  for i in range(steps):\n",
    "    step = i + 1\n",
    "    # Calculate loss with your real train function.\n",
    "    loss = 1 - 0.001 * step\n",
    "    if step % 100 == 0:\n",
    "      tf.summary.scalar('loss', loss, step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T19:28:56.565782Z",
     "iopub.status.busy": "2022-06-03T19:28:56.565274Z",
     "iopub.status.idle": "2022-06-03T19:28:56.730950Z",
     "shell.execute_reply": "2022-06-03T19:28:56.730140Z"
    },
    "id": "08QQD2j36TaI"
   },
   "outputs": [],
   "source": [
    "!ls tb/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xEL4yJe5qEhD"
   },
   "source": [
    "## 自动微分高级主题\n",
    "\n",
    "### 动态模型\n",
    "\n",
    "`tf.GradientTape` 也可以用于动态模型。下面这个[回溯线搜索](https://wikipedia.org/wiki/Backtracking_line_search)算法示例看起来就像普通的 NumPy 代码，但它的控制流比较复杂，存在梯度且可微分："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T19:28:56.734644Z",
     "iopub.status.busy": "2022-06-03T19:28:56.734092Z",
     "iopub.status.idle": "2022-06-03T19:28:56.738946Z",
     "shell.execute_reply": "2022-06-03T19:28:56.738372Z"
    },
    "id": "L518n5dkqEhE"
   },
   "outputs": [],
   "source": [
    "def line_search_step(fn, init_x, rate=1.0):\n",
    "  with tf.GradientTape() as tape:\n",
    "    # Variables are automatically tracked.\n",
    "    # But to calculate a gradient from a tensor, you must `watch` it.\n",
    "    tape.watch(init_x)\n",
    "    value = fn(init_x)\n",
    "  grad = tape.gradient(value, init_x)\n",
    "  grad_norm = tf.reduce_sum(grad * grad)\n",
    "  init_value = value\n",
    "  while value > init_value - rate * grad_norm:\n",
    "    x = init_x - rate * grad\n",
    "    value = fn(x)\n",
    "    rate /= 2.0\n",
    "  return x, value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gieGOf_DqEhK"
   },
   "source": [
    "### 自定义梯度\n",
    "\n",
    "自定义梯度是重写梯度的一种简单方法。在前向函数中，定义相对于输入、输出或中间结果的梯度。例如，下面是在后向传递中裁剪梯度范数的一种简单方法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T19:28:56.742173Z",
     "iopub.status.busy": "2022-06-03T19:28:56.741639Z",
     "iopub.status.idle": "2022-06-03T19:28:56.745199Z",
     "shell.execute_reply": "2022-06-03T19:28:56.744678Z"
    },
    "id": "-OwwsWUAqEhK"
   },
   "outputs": [],
   "source": [
    "@tf.custom_gradient\n",
    "def clip_gradient_by_norm(x, norm):\n",
    "  y = tf.identity(x)\n",
    "  def grad_fn(dresult):\n",
    "    return [tf.clip_by_norm(dresult, norm), None]\n",
    "  return y, grad_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JPLDHkF_qEhN"
   },
   "source": [
    "自定义梯度通常用来为运算序列提供数值稳定的梯度："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T19:28:56.748566Z",
     "iopub.status.busy": "2022-06-03T19:28:56.748029Z",
     "iopub.status.idle": "2022-06-03T19:28:56.751593Z",
     "shell.execute_reply": "2022-06-03T19:28:56.751061Z"
    },
    "id": "24WiLROnqEhO"
   },
   "outputs": [],
   "source": [
    "def log1pexp(x):\n",
    "  return tf.math.log(1 + tf.exp(x))\n",
    "\n",
    "def grad_log1pexp(x):\n",
    "  with tf.GradientTape() as tape:\n",
    "    tape.watch(x)\n",
    "    value = log1pexp(x)\n",
    "  return tape.gradient(value, x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T19:28:56.754602Z",
     "iopub.status.busy": "2022-06-03T19:28:56.754159Z",
     "iopub.status.idle": "2022-06-03T19:28:56.760906Z",
     "shell.execute_reply": "2022-06-03T19:28:56.760380Z"
    },
    "id": "n8fq69r9-B-c"
   },
   "outputs": [],
   "source": [
    "# The gradient computation works fine at x = 0.\n",
    "grad_log1pexp(tf.constant(0.)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T19:28:56.763738Z",
     "iopub.status.busy": "2022-06-03T19:28:56.763281Z",
     "iopub.status.idle": "2022-06-03T19:28:56.768447Z",
     "shell.execute_reply": "2022-06-03T19:28:56.767847Z"
    },
    "id": "_VFSU0mG-FSp"
   },
   "outputs": [],
   "source": [
    "# However, x = 100 fails because of numerical instability.\n",
    "grad_log1pexp(tf.constant(100.)).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-VcTR34rqEhQ"
   },
   "source": [
    "在此例中，`log1pexp` 函数可以通过自定义梯度进行分析简化。下面的实现重用了在前向传递期间计算的 `tf.exp(x)` 值，通过消除冗余计算使其变得更加高效："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T19:28:56.771566Z",
     "iopub.status.busy": "2022-06-03T19:28:56.771150Z",
     "iopub.status.idle": "2022-06-03T19:28:56.775465Z",
     "shell.execute_reply": "2022-06-03T19:28:56.774940Z"
    },
    "id": "Q7nvfx_-qEhS"
   },
   "outputs": [],
   "source": [
    "@tf.custom_gradient\n",
    "def log1pexp(x):\n",
    "  e = tf.exp(x)\n",
    "  def grad(dy):\n",
    "    return dy * (1 - 1 / (1 + e))\n",
    "  return tf.math.log(1 + e), grad\n",
    "\n",
    "def grad_log1pexp(x):\n",
    "  with tf.GradientTape() as tape:\n",
    "    tape.watch(x)\n",
    "    value = log1pexp(x)\n",
    "  return tape.gradient(value, x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T19:28:56.778616Z",
     "iopub.status.busy": "2022-06-03T19:28:56.778241Z",
     "iopub.status.idle": "2022-06-03T19:28:56.783340Z",
     "shell.execute_reply": "2022-06-03T19:28:56.782824Z"
    },
    "id": "5gHPKMfl-Kge"
   },
   "outputs": [],
   "source": [
    "# As before, the gradient computation works fine at x = 0.\n",
    "grad_log1pexp(tf.constant(0.)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T19:28:56.786280Z",
     "iopub.status.busy": "2022-06-03T19:28:56.785845Z",
     "iopub.status.idle": "2022-06-03T19:28:56.791076Z",
     "shell.execute_reply": "2022-06-03T19:28:56.790506Z"
    },
    "id": "u38MOfz3-MDE"
   },
   "outputs": [],
   "source": [
    "# And the gradient computation also works at x = 100.\n",
    "grad_log1pexp(tf.constant(100.)).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rnZXjfQzqEhV"
   },
   "source": [
    "## 性能\n",
    "\n",
    "在 Eager Execution 期间，计算会自动分流到 GPU。如果想控制计算运行的位置，可将其放在 `tf.device('/gpu:0')` 块（或 CPU 等效块）中："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T19:28:56.794195Z",
     "iopub.status.busy": "2022-06-03T19:28:56.793704Z",
     "iopub.status.idle": "2022-06-03T19:28:57.360958Z",
     "shell.execute_reply": "2022-06-03T19:28:57.360201Z"
    },
    "id": "Ac9Y64H-qEhX"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def measure(x, steps):\n",
    "  # TensorFlow initializes a GPU the first time it's used, exclude from timing.\n",
    "  tf.matmul(x, x)\n",
    "  start = time.time()\n",
    "  for i in range(steps):\n",
    "    x = tf.matmul(x, x)\n",
    "  # tf.matmul can return before completing the matrix multiplication\n",
    "  # (e.g., can return after enqueing the operation on a CUDA stream).\n",
    "  # The x.numpy() call below will ensure that all enqueued operations\n",
    "  # have completed (and will also copy the result to host memory,\n",
    "  # so we're including a little more than just the matmul operation\n",
    "  # time).\n",
    "  _ = x.numpy()\n",
    "  end = time.time()\n",
    "  return end - start\n",
    "\n",
    "shape = (1000, 1000)\n",
    "steps = 200\n",
    "print(\"Time to multiply a {} matrix by itself {} times:\".format(shape, steps))\n",
    "\n",
    "# Run on CPU:\n",
    "with tf.device(\"/cpu:0\"):\n",
    "  print(\"CPU: {} secs\".format(measure(tf.random.normal(shape), steps)))\n",
    "\n",
    "# Run on GPU, if available:\n",
    "if tf.config.experimental.list_physical_devices(\"GPU\"):\n",
    "  with tf.device(\"/gpu:0\"):\n",
    "    print(\"GPU: {} secs\".format(measure(tf.random.normal(shape), steps)))\n",
    "else:\n",
    "  print(\"GPU: not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RLw3IS7UqEhe"
   },
   "source": [
    "可以将 `tf.Tensor` 对象复制到不同设备来执行其运算："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T19:28:57.364421Z",
     "iopub.status.busy": "2022-06-03T19:28:57.363939Z",
     "iopub.status.idle": "2022-06-03T19:28:57.369985Z",
     "shell.execute_reply": "2022-06-03T19:28:57.369464Z"
    },
    "id": "ny6LX2BVqEhf"
   },
   "outputs": [],
   "source": [
    "if tf.config.experimental.list_physical_devices(\"GPU\"):\n",
    "  x = tf.random.normal([10, 10])\n",
    "\n",
    "  x_gpu0 = x.gpu()\n",
    "  x_cpu = x.cpu()\n",
    "\n",
    "  _ = tf.matmul(x_cpu, x_cpu)    # Runs on CPU\n",
    "  _ = tf.matmul(x_gpu0, x_gpu0)  # Runs on GPU:0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oA_qaII3-p6c"
   },
   "source": [
    "### 基准\n",
    "\n",
    "对于计算量繁重的模型（如在 GPU 上训练的 [ResNet50](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/eager/python/examples/resnet50)），Eager Execution 性能与 `tf.function` 执行相当。但是对于计算量较小的模型来说，这种性能差距会越来越大，并且在为有大量小运算的模型优化热代码路径方面，其性能还有待提升。\n",
    "\n",
    "## 使用函数\n",
    "\n",
    "虽然 Eager Execution 增强了开发和调试的交互性，但 TensorFlow 1.x 样式的计算图执行在分布式训练、性能优化和生产部署方面具有优势。为了弥补这一差距，TensorFlow 2.0 通过 `tf.function` API 引入了 `function`。有关详细信息，请参阅 [tf.function](https://render.githubusercontent.com/view/function.ipynb) 指南。"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "eager.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
